2021/5/19
- OMP image is massively messed up
  - huge values over 100,000 randomly getting put into the image
  - OMP is verified NOT to be outputting any erroneous values
  - Sample points verified NOT to be located in outer border
  - Large ranges of the entire OMP image set to garbage for no obvious reason


2021/5/18
- fix coarseDM stuff
  - DONE: verify that OMP is returning correct values
  - update interpolation function
    - 2 channel images in opencv?
    - ISSUE: OMP output has range of 0-1680
      - have been using 8UC1 images -> 8bit unsigned int has max of 255
        - TODO:


2021/5/10
Qs:
  - interpolation
    - what is expected range of OMP?
      - how to map to value that can be divided by 13 to get x and y?
    - what should I do about large values?
    - how to map interpolation average to colors?
    - interpolation image = integers or floats?
      - issue of forward vs backward DM comparison threshold = 2 pixels
  - forward vs backward DM
    - use same set of sample points from forward DM?
    - go over every point in forward DM when comparing to backward DM,
      or just sample points?


- PLAN:
  - look into what is happening wrt images containing artifacts/errors
  - get function to map a value within one range to another range
  - figure out range of OMP output (no idea what's going on there)
  - figure out how to map interpolation avg value to something that can be divided by 13
    - current values are max 0.5, and paper expects range of [-5,5] for x and y
  - determine how paper is using x and y value to determine interpolation color
  - verify that interpolation image should be made of integer values
    - since comparison threshold is 2 pixels, makes this confusing
      - could easily be either floats or ints
  - create new 3-channel interpolation images in ROS callback
  - look up how to set point to RGB color / however the paper is doing color
  - run and see how it looks
  - get displacement map generation packaged up into a function within coarseDM.cpp itself
  - in callback, just create DM for forward and back
  - new function in coarseDM to compare forward in back, return fixed image
  - move on to fine depth map: hilbert sfc and permutation table


- TODO: colorized interpolation
  - y = omp value / 13
  - x = omp value % 13
  - not really sure how this will work; only seeing max values around ~0.5
    - maybe this is scaled to 0.0 - 1.0?
      - paper uses range of -5 - 5 for x and y (why?)
        maybe just multiply values by 5 -> map to range of 0-255 for color image?
          - assuming 0-255 because this is the coarse depth map
  - paper:
     0,  0 = white
     5,  5 = orange-ish brown?
    -5,  5 = green
     5, -5 = purple
    -5, -5 = blue
     likely not scaling individual RGB values on x and y
  - tried multiplying by 255 (float -> int), then divide / mod by 13
    - values a lot bigger than 5...

- just setting massive OMP values to 0
  - better to have less data than mess up everything
  - NOTE: massive values still showing up in interpolation? doesnt make any sense
- ISSUE: very negative values still coming out of OMP, messing up interpolation
  - causes bins to be extremely large:
    current point: 724, 226
    min: -1.72557e+35
    max: 0.676281
    bin width: 8.62786e+33
- ISSUE: errors in image saving seems to be an issue, no idea why its so inconsistent
- TODO: forward vs backward coarse DM:
  - TODO: figure out whether this is looking at every pixel in the DM image, or just sample points?
    - for backward DM should i generate new set of sample points, or just use the set used for the forward DM?
  - swap the images and generate another DM
    - NOTE: operating under assumption that backwards DM should be negative of forwards DM
      - TODO: verify this assumption
    - comparison:
      - "forward DM says that this pixel has shifted 2 pixels to the left"
      - then check at the location 2 pixels to the left within the backwards DM,
        and make sure it says that "this pixel has shifted 2 pixels to the right"?
      - if these statements are within 2 pixels of each other, the forward DM esitmate is kept
        otherwise forward DM is discarded
    - ROS node callback needs to be cleaned up a LOT
    - TODO: make function to take forwards + backwards DM and do comparison
- TODO: hilbert sfc algorithm for rectangular image (read paper)
- TODO: fine displacement
  - after we have this refined set of displacements, we run it through an adaptive filter
  - goal: to ensure that convolution kernel used in this filter changes as slowly as possible
    - called a "slow evolution"
  - to do this, we try to process coarse DM values such that the change between each pixel
    is minimized
    - create a "permutation table": a fancy / organized histogram
    - the bins within the table are ordered to minimize differences between bins
      - AKA the values within each bin are ordered this time around
      - NOTE: paper says there are "M" bins in total for this histogram
        - M referenced previously as search size for the OMP dictionary matrix
        - M = 41^2 = 1681 (thats a LOT of bins)
        - still confused on how many bins the interpolation function should have...
    - algorithm for permutation table:
      - scan DM along hilbert sfc pixel by pixel
      - each pixel added into bin based on displacement value
        - (save its coordinates / position)
      - after scan, each bin now has positions of all pixels with same displacement
        - seems like each displacement value has its own bin...
          - NOTE: maybe this is how the interpolation histogram should be done???
      - each bin is re-ordered according to position along hilbert SFC
      - each bin is read from smallest to greatest -> slowest possible kernel evolution
    - filter is a Recursive Least Squares adaptive filter
    - left off at bottom left after fig 5
- NOTE: desired range of coordinates
  - img height: 338 with 41 px border -> actually 256
    img width : 784 with 41 px border -> actually 702
  - y: [41,297]
  - x: [41,743]
- TODO: bad image encoding is definitely messing up interpolation
  - compare frame12 and interp12 in queue/save_error: shifted "duplicate" put on to frame12
    is reflected in interpolation output
  - seems like weird errors are propagating throughout subsequent images?
- NOTE: since this is a coarse displacement map, shouldn't the interpolation image
  be all int values?
    - main issue: OMP output = float with unknown range
      - if this was guaranteed to be limited to 0-1.0, could easily translate to 0-255






2021/5/9
- figured out crashing issue
  - there are negative values in the OMP image
  - when making histogram in the interpolation function, have this line:
    int hist_index = (int) (val / binWidth)
    where val = value at current pixel
  - results in negative hist_index value -> segfault when try to access index of histogram (array of bins)
  - TODO:
    - figure out what to do with these negative values / how to arrange histogram array
    - logically, smallest index histogram -> most negative value
    - ISSUE: opencv's MinMaxLoc does not work for negative values!
      - need to go through and pick out min / max manually?
    - have some ideas to make it scale with number of bins...
      worst case just hardcode it for 20 bins
  - ISSUE: still getting NaN values from OMP still... causing more segfaults
    - TODO: if output of OMP is NaN just set it to zero
    - not sure whether massive big / small values = NaN? What is causing this??
    - need to look up how to check for NaN



2021/5/6
- guarantee image queue
  - idea: just save the entire bag to a folder of images
    - run it once, then change main to just loop through the folder
    - doesn't translate well to ROS...
  - idea: make vector / queue of images that must be filled to some size
          before doing the rest of the callback function
- NOTE: 213 messages in the bag file currently being used
  - try skipping the first 100 messages to get to point with movement
- DONE: keeps crashing after processing 3 images
  - specifically right after OMP is finished. output:
    sample points elapsed time: 0.419463s
    OMP thread jobs made in: 0.00185479s
    OMP finished in: 311.471s
    interpolation finished in: 0.528147s
    sample points elapsed time: 0.443377s
    OMP thread jobs made in: 0.00185737s
    OMP finished in: 319.736s
    interpolation finished in: 0.573632s
    sample points elapsed time: 0.429242s
    OMP thread jobs made in: 0.00178101s
    OMP finished in: 318.614s
    Segmentation fault (core dumped)


2021/5/4
- DONE: new sample point selection
  - Probability Density Function, from wikipedia:
    a probability density function (PDF), or density of a continuous random variable,
    is a function whose value at any given sample (or point) in the sample space
    can be interpreted as providing a relative likelihood that the value of
    the random variable would equal that sample
  - So basically the higher the intensity, the more likely it is for a random point
    to equal that intensity?
- DONE: confirm that the interpolation function is working / able to draw
  - think there's an issue with sample point selection
    - currently just generating random coordinates and saving them if the intensity
      is above a defined threshold
    - paper: "the ref image intensity is used as a probability density function"
      - this means that the intensities of the pixel values are essentially made into
        a histogram / bell curve type of thing
    - paper: generating sample points stops when |X_sample| = (1/17) |X|
      - thought that this meant the NUMBER of sample points = 1/17 the number of pixels in the image
      - it might actually mean that the TOTAL INTENSITY of the sample points = 1/17 total intensity of image

2021/5/2
- turn interpolation image from clone -> make entirely new image

2021/4/29
meeting
  - random points: HSFC number line vs random x and random y?
  - for-each loop bug
  - making custom histogram for interpolation
    - number of histogram bins?
  - testing with low sample points -> no good
    - number of sample points?
  - scaling xHat output to range of 0.0-1.0?

to do
  - optimization
    - find which processes are taking the most time
      - DONE: use chrono to measure time taken for:
        - OMP estimation of each point?
        - OMP estimation of all points
        - gathering sample points
        - interpolatiion of all points
        https://www.geeksforgeeks.org/chrono-in-c/
    - DONE: parallelize OMP estimation
      - https://www.geeksforgeeks.org/multithreading-in-cpp/
      - probably divide up the sample_points array into parts
        for each thread to handle
      - double check params and stuff (adding const when necessary)
        to make sure nothing is getting changed / everything is concise
  - TODO: make a DEBUG constant to enable / disable debug output
  - interpolation
    - TODO: make interpolation squares be drawn on a separate image
      - how to parallelize this?
  - DONE: improve sampling to be a proper PDF

2021/4/27
- interpolation
  - opencv calcHist() just outputs a 1D array with the number of pixels in each bin
    - NOTE: output doesn't contain the actual pixel values of each pixel in each bin
    - need to figure out a different approach
- clean up code
- Q: looking at OMP coarse DM stuff, "only the displacement d(ξ) corresponding to
the coefficient with the highest magnitude is kept for our further
processing"
  - say xHat has -1.2 and 1.1 in it. -1.2 has highest magnitude -> do I return -1.2 or 1.2?
- NOTE: img height: 338 with 41 px border -> actually 256
        img width : 784 with 41 px border -> actually 702
        179712 pixels -> 10571 sample points? (1/17th)
        img.cols -> x, img.rows -> y



2021/4/25
- DONE change how OMP translates to image
  - now want to have the highest absolute value from output
    set to pixel value of what was passed in
    - still have the pass by reference stuff get changed,
      OR just have the OMP function return that highest value?
    - returning just highest value would be way simpler -> do that

- interpolation
  - for each pixel chosen for OMP estimation, create a 13 x 13 box around it
  - make a histogram based on this box. choose bin with highest number.
    - how many bins?
    - DONE: change chosen OMP coords to a vector you push_back into
      - allows you to switch easily between grid of coordinates
        and what they actually use in the paper
  - set all pixels in output image within the 13 x 13 box to the average value of the chosen bin
    - color scaling?

- DONE coordinate selection
  - ref image intensity used as probability density function to generate sample points
    - basically you just want to choose random points that have a high intensity
    - choose random point -> keep if it's intensity is above threshold
      - DONE: make histogram of ref image intensities to determine appropriate threshold
        - basic distribution of point intensities:
          between 0 and 0.25:   0
          between 0.25 and 0.5: 230905
          between 0.5 and 0.75: 31244
          between 0.75 and 1.0: 2843
          total of 264992 points
        - chosen threshold of 0.75?
        - num chosen points = 1/17 * num pixels in ref image?
          - would be 15588 points in our case -> lower the threshold?
  - 2 references listed here
    - C. Schretter and H. Niederreiter, “A direct inversion method for non-
      uniform quasi-random point sequences,” Monte Carlo Methods Appl.,
      vol. 19, no. 1, pp. 1–9, 2013
    - C.-C. Wu and Y.-I. Chang, “Approximately even partition algorithm for
      coding the Hilbert curve of arbitrary-sized image,” IET Image Process.,
      vol. 6, no. 6, pp. 746–755, 2012
  - NOTE: points are initially randomly chosen by picking random number along
          Hilbert Space-Filling curve! Instead of generating 2 random points?
  - TODO: add HSFC (for rectangular areas)? or just randomly generate x and y?



2021/4/22
- fix: converting original cartesian to float image didnt actually change the pixel values
  needed to include /= 255 to scale values
- fix: result of OMP estimation was saving weird values in the column dedicated to error vector
- fix xHat = 0 issue. to do so, look at xTemp, supports, dictASupport
	- xTemp has some negative values? not sure if this is normal
- read paper to develop a plan of action

2021/4/17
- pad sonar image with 41 black pixels
- set up collage of OMP outputs
- read research paper to figure out how many points to do OMP at

2021/4/3
- fixed search areas in getGamma and dictionaryMatrix
	- for loop needed to use <= instead of <
- NOTE: double check how to use coordinates in openCV (x, y) or (y, x)
- convert everything to floats if possible
- ISSUE:
	- getting strange values in targetY gamma
		- values are either very very small (close to 0), or huge
		- how does converting the opencv image effect scaling of grayscale values?
			- when i write "float" in c++, does it expect a 32bit float that is being used by openCV?
	- norm of error vector = NaN?
		- likely due to huge values, may be reaching limit of float datatype?
	- original image returned by mitchell's imageproc file is CV_8UC1
		- make sure it can convert correctly
	- bunch of values in error vector are getting set to NaN!
		- error = targetY - (dictA * xHat);
		- check that all values in targetY, dictA, xHat are not equal to NaN!
			- have a feeling that it may be due to not doing any padding on the image
			  dictionary matrix may be going off the image, but I assume that would throw
				an error rather than just set to NaN


2021/4/1
- code working better now
- issue updating xHat
	- "For every index in S (support vector), xHat = xTemp. otherwise xHat == 0"
	- so if column 700 was chosen in the first iteration (AKA support = [700, null, null, ...]),
	  and I am currently looping over support vector with variable j (j currently = 0), do I set
		xHat[700] = xTemp[700]? or:
		xHat[dictA.col(700)[0]] = xTemp[dictA.col(700)[0]]


2021/3/31
- stuck at turning error vector into a float datatype
	- when I do, the multiplication at line 114 stops compiling bc of mixing datatypes
- also realized i forgot to do the pseduo inverse of dictA for x_temp (as detailed in the OMP writeup)

2021/3/30
- NOTE: matrix notation is row, column
- issue of using Dynamic matrices in Eigen
	- for any multiplication, need to know that the dimensions of the matrices will work?
	- ! may need to change vectors to 1 x Dynamic matrices
		- Assertion `lhs.cols() == rhs.rows()
		- xHat cols: 1 xHat rows: 169 dictA rows: 169
- Eigen stack memory limit
	- trying to use big matrices -> errors
	- need to circumvent (i think need to change compilation settings? maybe cmake)
	-
For speeding up matrix multiplication:
https://stackoverflow.com/questions/39723461/vector-matrix-multiplication-with-eigen
1. try converting all vectors to 1 x Dynamic Matrices
2. Need to pass parameters by REFERENCE, not by value!
left off: having trouble around line 114 in coarseDM
can't get dictionary matrix (169 by 1681) to multiply with xHat (169 by 1)

Still can't figure out why it's broken... error message:
xHat cols: 1
xHat rows: 169
dictA cols: 1681
dictA rows: 169
sonar_listener: /usr/include/eigen3/Eigen/src/Core/Product.h:95: Eigen::Product<Lhs, Rhs, Option>::Product(const Lhs&, const Rhs&) [with _Lhs = Eigen::Matrix<int, -1, -1>; _Rhs = Eigen::Matrix<int, -1, -1>; int Option = 0; Eigen::Product<Lhs, Rhs, Option>::Lhs = Eigen::Matrix<int, -1, -1>; Eigen::Product<Lhs, Rhs, Option>::Rhs = Eigen::Matrix<int, -1, -1>]: Assertion `lhs.cols() == rhs.rows() && "invalid matrix product" && "if you wanted a coeff-wise or a dot product use the respective explicit functions"' failed.
Aborted (core dumped)




- order of hilbert curve = length or width of sqaure it is traversing
	- 8 x 8 square can have every coordinate filled by a N = 8 curve
	- how do you do a hilbert curve in a rectangle?

notes on OMP
- Ax = y
	- A = dictionary matrix
	- x = unknown vector (will be 1 x 169, a column of A)
	- y = target vector (1 x 169 gamma vector centered on matching pixel)
- approach: instead attempt to solve:
- y - Ax = e
	- e = error vector. if x exists (highly unlikely), e would = 0
	- instead we are looking for the best possible value of x, and
	  include e to make up for the fact that it isn't perfect
SETUP OMP algorithm
- output vector x^ (x-hat), our proposed solution to x
	- init as 0, iterate on it throughout algo
- error vector e
	- init as y (if x^ = 0, then e must = y)
- support vector S
	- init empty. it will eventually contain index of A we want for
	  our solution
BEGIN LOOP
	- loop ends once error is small enough (ex: norm of e > 0.1)
		- what does norm mean
- loop through A to find index j that is maximally correlated with e
	- at each index j, calculate:
		- abs((A_j) ^ transpose e) / norm(A_j)
		- "the norm of the matrix product between A_j transpose
		  and the current error, divided by euclidean norm of A_j"
	- the max output of the above calculation will be the vector we
	  append to S
		- by "append" it means add the specific column to S
		- ex: if first loop finds j = 2 is best, S = [2]
		  if second loop finds j = 5, S = [2,5]
	- now update x^
		- take Moore-Penrose pseudo-inverse of A
		  = (A_transpose A) ^ (inverse)A_transpose
			- available on most any lin alg library
		- multiply y by this value to get x_temp
			- x_temp = A_pseudo_inverse * y
(?)		- can now cast x_temp directly to x^
(?)			- for every index in S, set x_hat == x_temp
	- update error vector
		- e = y - A*x^
	- check norm(e) << threshold OR exceeded max iterations, exit if needed
